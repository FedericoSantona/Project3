{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h8/j5sdk6fd36l0dzr4fw3395h80000gn/T/ipykernel_76226/2715407926.py:4: RuntimeWarning: invalid value encountered in log\n",
      "  eta = np.log(-4)\n",
      "/var/folders/h8/j5sdk6fd36l0dzr4fw3395h80000gn/T/ipykernel_76226/2715407926.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  lmb = np.log(-5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from CNN_with_XGBoost import *\n",
    "\n",
    "eta = np.log(-4)\n",
    "lmb = np.log(-5)\n",
    "batch_size = 128\n",
    "n_epochs = 300\n",
    "target_num_images = 1000  # Set your target number of images per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Found 7178 files belonging to 7 classes.\n",
      "x train shape: (28709, 48, 48, 1)\n",
      "t train shape: (28709, 7)\n",
      "x test shape: (7178, 48, 48, 1)\n",
      "t test shape: (7178, 7)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tensorflow import keras as tfk\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# print python version\n",
    "# print(\"Python VERSION:\", sys.version)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        Description:\n",
    "        ------------\n",
    "            CNN application to the emotions dataset, remeber to change the path \n",
    "            to the dataset in the beginning of the code.\n",
    "\n",
    "        Parameters to tune:\n",
    "        ------------\n",
    "            I  Architecture of the CNN( Number and types of layers)\n",
    "            II  Dimensions and number of the kernels (height and width) used for convolution and pooling\n",
    "            III stride in the convolutional layers and pooling layers, padding or no padding\n",
    "            IV  Numbers of epochs and batches ( 2 types of batches are used, one for the GD(in the fit function) and one for data preprocessing)\n",
    "            V   Learning rate and regularization parameter ( lambda)\n",
    "            VI  Activation functions ( sigmoid, tanh, relu, leaky relu, softmax)\n",
    "            VII  Number of neurons in the fully connected layers\n",
    "        \"\"\"\n",
    "\n",
    "# Path to the zip file and extraction directory\n",
    "zip_path = r\"/Users/carmen/archive.zip\"\n",
    "extraction_path = r\"/Users/carmen/dataset\"\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "# Set up directories\n",
    "train_dir = os.path.join(extraction_path, 'train')\n",
    "test_dir = os.path.join(extraction_path, 'test')\n",
    "\n",
    "# Define image dimensions\n",
    "img_width, img_height = 48, 48  # You can adjust this based on your specific dataset\n",
    "\n",
    "\n",
    "# Load images using image_dataset_from_directory\n",
    "train_dataset = tfk.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    color_mode='grayscale', # or 'rgb' for colored images\n",
    "    label_mode='categorical',  # or 'binary' if you have two classes\n",
    "    image_size=(img_width, img_height))\n",
    "\n",
    "\n",
    "test_dataset = tfk.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    color_mode='grayscale', # or 'rgb' for colored images\n",
    "    label_mode='categorical',  # or 'binary' if you have two classes\n",
    "    image_size=(img_width, img_height))\n",
    "\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "# You can add your preprocessing layers here\n",
    "preprocessing_model = tfk.Sequential([\n",
    "    tfk.layers.Rescaling(1./255),  # Rescale pixel values\n",
    "    # Add any additional preprocessing layers here\n",
    "])\n",
    "\n",
    "\n",
    "# Apply the preprocessing to the dataset\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocessing_model(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (preprocessing_model(x), y))\n",
    "#train_dataset = train_dataset.take(200)\n",
    "#test_dataset = test_dataset.take(40)\n",
    "\n",
    "\n",
    "# To get the labels from the train dataset\n",
    "train_labels = []\n",
    "for _, labels in train_dataset:\n",
    "    train_labels.extend(labels.numpy())\n",
    "\n",
    "# Do the same for the test dataset\n",
    "test_labels = []\n",
    "for _, labels in test_dataset:\n",
    "    test_labels.extend(labels.numpy())\n",
    "\n",
    "# Now train_labels and test_labels contain the labels for their respective datasets\n",
    "\n",
    "#Split the images from their target\n",
    "\n",
    "x_train_list = []\n",
    "t_train_list = []\n",
    "\n",
    "\n",
    "# Iterate through the training dataset\n",
    "for images, labels in train_dataset:\n",
    "    # Append images and labels to the respective lists\n",
    "    x_train_list.append(images.numpy())\n",
    "    t_train_list.append(labels.numpy())\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_train = np.concatenate(x_train_list, axis=0)\n",
    "t_train = np.concatenate(t_train_list, axis=0)\n",
    "\n",
    "# Do the same for the test dataset\n",
    "x_test_list = []\n",
    "t_test_list = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    x_test_list.append(images.numpy())\n",
    "    t_test_list.append(labels.numpy())\n",
    "\n",
    "x_test = np.concatenate(x_test_list, axis=0)\n",
    "t_test = np.concatenate(t_test_list, axis=0)\n",
    "\n",
    "\n",
    "# Now you can use x_train, t_train, x_test, and t_test with your custom CNN\n",
    "\n",
    "print(\"x train shape:\", x_train.shape)\n",
    "print(\"t train shape:\", t_train.shape)\n",
    "print(\"x test shape:\", x_test.shape)\n",
    "print(\"t test shape:\", t_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: main() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "main(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model(x_train, t_train, x_test, t_test, max_depth=10, eta=0.3, num_class=7, n_boosts=20):\n",
    " tensorflow_model(x_train, t_train, x_test, t_test, \n",
    "                     batch_size=64, epochs=10, \n",
    "                     eta = 0.0001, l2_lambda = 0.0001, \n",
    "                     save_results = False, summary = False):\n",
    "    \n",
    "def augment_images(image, augmentation_datagen, aug_count) -> list:\n",
    "def balance_classes(images, labels, num_samples, augmentation_datagen) -> tuple:\n",
    "#def initialize_data(batch_size) -> tuple:\n",
    "def downscale(scale_factor=6):\n",
    "def plot_dataset_balance(labels):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonkurs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
